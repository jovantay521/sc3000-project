# Balancing Cartpole(v1)

## Description

This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in “Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem”. A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart. ([Source](https://gymnasium.farama.org/environments/classic_control/cart_pole/))

Our main learning objectives of the assignment was to:
- develop Reinforcement Learning (RL) agent using
  - Q-Learning
  - Deep Q-Learning
- demonstrate effectiveness of RL agent

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Credits](#credits)

## Installation

Clone the project
```bash
git clone https://github.com/jovantay521/sc3000-project.git
```

## Usage

Open jupyter notebook in editor of choice \
Example (Visual Studio Code):
```
code cartpole-q-learning.ipynb
code cartpole-dqn.ipynb
```


## Credits
- Tay Jovan (U2223490G) @jovantay521 - Q Learning code (33.3%)
- Nicholas Koh (U2222992D) @Nic-Koh - Deep Q Learning code (33.3%)
- Timothy Chang (U2220136J) @timothychangeke - Q learning & Deep Q Learning code refactoring & markdown (33.3%)
