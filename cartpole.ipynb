{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation\\\n",
    "[Basic Usage - Gymnasium Documentation](https://gymnasium.farama.org/content/basic_usage/)\\\n",
    "[Cart Pole - Gymnasium Documentation](https://gymnasium.farama.org/environments/classic_control/cart_pole/#cart-pole)\\\n",
    "[Cart Pole Control Environment in OpenAI Gym (Gymnasium)](https://aleksandarhaber.com/cart-pole-control-environment-in-openai-gym-gymnasium-introduction-to-openai-gym/)\\\n",
    "[Cartpole with Q-Learning Algorithm](https://aleksandarhaber.com/q-learning-in-python-with-tests-in-cart-pole-openai-gym-environment-reinforcement-learning-tutorial/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (69.1.1)\n",
      "Requirement already satisfied: ez_setup in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.0rc0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.0-rc0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.0rc0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (3.0.5)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pygame in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jovan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jovan\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "!pip install gymnasium \n",
    "!pip install --upgrade setuptools\n",
    "!pip install ez_setup\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib\n",
    "!pip install pygame\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from tqdm import tqdm\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# display plots below code\n",
    "%matplotlib inline\n",
    "\n",
    "# Set error logging level to 'ERROR'\n",
    "# logger.set_level(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "{'render_modes': ['human', 'rgb_array'], 'render_fps': 50}\n",
      "human\n",
      "(-inf, inf)\n",
      "EnvSpec(id='CartPole-v1', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'render_mode': 'human'}, namespace=None, name='CartPole', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv')\n"
     ]
    }
   ],
   "source": [
    "# generate our environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "# env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# basic info\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n",
    "print(env.metadata)\n",
    "print(env.render_mode)\n",
    "print(env.reward_range)\n",
    "print(env.spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 1\n",
      "cart position: -0.01957808807492256\n",
      "cart velocity: 0.2389117181301117\n",
      "pole angle: -0.022795235738158226\n",
      "pole angular velocity: -0.30435463786125183\n",
      "reward: 1.0\n",
      "terminated: False\n",
      "truncated: False\n"
     ]
    }
   ],
   "source": [
    "# running one step\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset() # initial state\n",
    "# observation: cart position, cart velocity, pole angle, pole angular velocity\n",
    "\n",
    "STEPS = 1\n",
    "\n",
    "for _ in (range(STEPS)):\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    print(f\"action: {action}\") # 0: push cart left, 1: push cart right\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    print(f\"cart position: {observation[0]}\")\n",
    "    print(f\"cart velocity: {observation[1]}\")\n",
    "    print(f\"pole angle: {observation[2]}\")\n",
    "    print(f\"pole angular velocity: {observation[3]}\")\n",
    "    print(f\"reward: {reward}\")\n",
    "    print(f\"terminated: {terminated}\")\n",
    "    print(f\"truncated: {truncated}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running one episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m STEP_COUNT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPISODE_COUNT):\n\u001b[1;32m----> 5\u001b[0m     observation, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# initial state\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     total_reward \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m     total_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jovan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:75\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jovan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:61\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jovan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:59\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jovan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:209\u001b[0m, in \u001b[0;36mCartPoleEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_beyond_terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), {}\n",
      "File \u001b[1;32mc:\\Users\\Jovan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:299\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m gfxdraw\u001b[38;5;241m.\u001b[39mhline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen_width, carty, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    301\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "EPISODE_COUNT = 1\n",
    "STEP_COUNT = 500\n",
    "\n",
    "for episode in range(EPISODE_COUNT):\n",
    "    observation, info = env.reset() # initial state\n",
    "    total_reward = []\n",
    "    total_step = 0\n",
    "    for step in range(STEP_COUNT):\n",
    "        random_action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        total_step += 1\n",
    "        total_reward.append(reward)\n",
    "        print(f\"episode {episode}, step {step}, action: {action}, observation: {observation}\")\n",
    "        if terminated or truncated:\n",
    "            print(f\"Summary: total step: {total_step}, total reward: {np.sum(total_reward)}\")\n",
    "            observation, info = env.reset()\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running 10 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, step 0, action: 0, observation: [-0.04537159 -0.23059562 -0.04624301  0.24467452]\n",
      "episode 0, step 1, action: 0, observation: [-0.0499835  -0.4250276  -0.04134952  0.52242017]\n",
      "episode 0, step 2, action: 0, observation: [-0.05848405 -0.6195439  -0.03090111  0.8017919 ]\n",
      "episode 0, step 3, action: 0, observation: [-0.07087493 -0.8142288  -0.01486528  1.0845963 ]\n",
      "episode 0, step 4, action: 0, observation: [-0.08715951 -1.0091515   0.00682665  1.3725778 ]\n",
      "episode 0, step 5, action: 0, observation: [-0.10734253 -1.2043581   0.03427821  1.667388  ]\n",
      "episode 0, step 6, action: 0, observation: [-0.1314297  -1.3998615   0.06762596  1.9705466 ]\n",
      "episode 0, step 7, action: 0, observation: [-0.15942693 -1.595629    0.1070369   2.2833934 ]\n",
      "episode 0, step 8, action: 0, observation: [-0.19133951 -1.7915672   0.15270476  2.6070275 ]\n",
      "episode 0, step 9, action: 0, observation: [-0.22717085 -1.987505    0.20484532  2.942235  ]\n",
      "episode 0, step 10, action: 0, observation: [-0.26692095 -2.1831727   0.26369002  3.2894046 ]\n",
      "Summary: total step: 11, total reward: 11.0\n",
      "episode 1, step 0, action: 0, observation: [ 0.00738148 -0.1689836   0.0370154   0.28335324]\n",
      "episode 1, step 1, action: 0, observation: [ 0.00400181 -0.3646134   0.04268247  0.587477  ]\n",
      "episode 1, step 2, action: 0, observation: [-0.00329046 -0.5603063   0.05443201  0.89329386]\n",
      "episode 1, step 3, action: 0, observation: [-0.01449659 -0.7561226   0.07229789  1.2025784 ]\n",
      "episode 1, step 4, action: 0, observation: [-0.02961904 -0.95210105  0.09634946  1.5170152 ]\n",
      "episode 1, step 5, action: 0, observation: [-0.04866106 -1.1482475   0.12668976  1.8381531 ]\n",
      "episode 1, step 6, action: 0, observation: [-0.07162601 -1.3445212   0.16345282  2.1673515 ]\n",
      "episode 1, step 7, action: 0, observation: [-0.09851643 -1.5408196   0.20679985  2.5057158 ]\n",
      "episode 1, step 8, action: 0, observation: [-0.12933283 -1.7369608   0.25691417  2.8540256 ]\n",
      "Summary: total step: 9, total reward: 9.0\n",
      "episode 2, step 0, action: 0, observation: [-0.03670258 -0.21715626  0.05014522  0.32677853]\n",
      "episode 2, step 1, action: 0, observation: [-0.04104571 -0.41295493  0.05668079  0.6348439 ]\n",
      "episode 2, step 2, action: 0, observation: [-0.04930481 -0.6088198   0.06937767  0.9448245 ]\n",
      "episode 2, step 3, action: 0, observation: [-0.0614812  -0.8048042   0.08827416  1.2584747 ]\n",
      "episode 2, step 4, action: 0, observation: [-0.07757729 -1.0009378   0.11344365  1.5774485 ]\n",
      "episode 2, step 5, action: 0, observation: [-0.09759604 -1.197214    0.14499262  1.9032512 ]\n",
      "episode 2, step 6, action: 0, observation: [-0.12154032 -1.3935758   0.18305764  2.237182  ]\n",
      "episode 2, step 7, action: 0, observation: [-0.14941184 -1.5898999   0.22780128  2.5802665 ]\n",
      "Summary: total step: 8, total reward: 8.0\n",
      "episode 3, step 0, action: 0, observation: [-0.00433343 -0.23584835 -0.0487946   0.2940629 ]\n",
      "episode 3, step 1, action: 0, observation: [-0.00905039 -0.4302419  -0.04291334  0.57096624]\n",
      "episode 3, step 2, action: 0, observation: [-0.01765523 -0.6247366  -0.03149401  0.8498271 ]\n",
      "episode 3, step 3, action: 0, observation: [-0.03014996 -0.8194153  -0.01449747  1.1324426 ]\n",
      "episode 3, step 4, action: 0, observation: [-0.04653827 -1.0143445   0.00815138  1.4205436 ]\n",
      "episode 3, step 5, action: 0, observation: [-0.06682516 -1.2095664   0.03656225  1.7157631 ]\n",
      "episode 3, step 6, action: 0, observation: [-0.09101649 -1.4050881   0.07087751  2.0195966 ]\n",
      "episode 3, step 7, action: 0, observation: [-0.11911825 -1.6008694   0.11126944  2.3333519 ]\n",
      "episode 3, step 8, action: 0, observation: [-0.15113564 -1.7968074   0.15793648  2.658087  ]\n",
      "episode 3, step 9, action: 0, observation: [-0.18707179 -1.9927182   0.21109822  2.9945362 ]\n",
      "Summary: total step: 10, total reward: 10.0\n",
      "episode 4, step 0, action: 0, observation: [-0.01999556 -0.24339032 -0.0089282   0.33706358]\n",
      "episode 4, step 1, action: 0, observation: [-0.02486336 -0.4383841  -0.00218692  0.6269177 ]\n",
      "episode 4, step 2, action: 0, observation: [-0.03363104 -0.6334754   0.01035143  0.9189111 ]\n",
      "episode 4, step 3, action: 0, observation: [-0.04630055 -0.82873577  0.02872965  1.2148292 ]\n",
      "episode 4, step 4, action: 0, observation: [-0.06287527 -1.0242164   0.05302624  1.5163745 ]\n",
      "episode 4, step 5, action: 0, observation: [-0.08335959 -1.2199383   0.08335372  1.825127  ]\n",
      "episode 4, step 6, action: 0, observation: [-0.10775836 -1.4158801   0.11985626  2.142497  ]\n",
      "episode 4, step 7, action: 0, observation: [-0.13607596 -1.611964    0.1627062   2.469666  ]\n",
      "episode 4, step 8, action: 0, observation: [-0.16831525 -1.808038    0.21209952  2.8075175 ]\n",
      "Summary: total step: 9, total reward: 9.0\n",
      "episode 5, step 0, action: 0, observation: [ 0.02461196 -0.15522036  0.02651237  0.25506863]\n",
      "episode 5, step 1, action: 0, observation: [ 0.02150756 -0.35071063  0.03161374  0.5559947 ]\n",
      "episode 5, step 2, action: 0, observation: [ 0.01449335 -0.54626185  0.04273364  0.8584679 ]\n",
      "episode 5, step 3, action: 0, observation: [ 0.00356811 -0.74193907  0.059903    1.1642755 ]\n",
      "episode 5, step 4, action: 0, observation: [-0.01127067 -0.93778753  0.0831885   1.4751223 ]\n",
      "episode 5, step 5, action: 0, observation: [-0.03002642 -1.1338216   0.11269096  1.7925857 ]\n",
      "episode 5, step 6, action: 0, observation: [-0.05270286 -1.330012    0.14854267  2.1180658 ]\n",
      "episode 5, step 7, action: 0, observation: [-0.07930309 -1.5262707   0.19090398  2.4527233 ]\n",
      "episode 5, step 8, action: 0, observation: [-0.10982851 -1.722434    0.23995845  2.797408  ]\n",
      "Summary: total step: 9, total reward: 9.0\n",
      "episode 6, step 0, action: 0, observation: [ 0.02130832 -0.2018988   0.01749915  0.30795023]\n",
      "episode 6, step 1, action: 0, observation: [ 0.01727035 -0.39726567  0.02365815  0.60610014]\n",
      "episode 6, step 2, action: 0, observation: [ 0.00932503 -0.5927103   0.03578015  0.9061399 ]\n",
      "episode 6, step 3, action: 0, observation: [-0.00252917 -0.788298    0.05390295  1.2098508 ]\n",
      "episode 6, step 4, action: 0, observation: [-0.01829513 -0.984073    0.07809997  1.5189265 ]\n",
      "episode 6, step 5, action: 0, observation: [-0.03797659 -1.1800475   0.10847849  1.8349303 ]\n",
      "episode 6, step 6, action: 0, observation: [-0.06157754 -1.3761892   0.1451771   2.1592436 ]\n",
      "episode 6, step 7, action: 0, observation: [-0.08910133 -1.5724056   0.18836197  2.4930043 ]\n",
      "episode 6, step 8, action: 0, observation: [-0.12054944 -1.7685269   0.23822206  2.8370345 ]\n",
      "Summary: total step: 9, total reward: 9.0\n",
      "episode 7, step 0, action: 0, observation: [ 0.02076901 -0.19581912 -0.02556216  0.23896623]\n",
      "episode 7, step 1, action: 0, observation: [ 0.01685262 -0.39056674 -0.02078284  0.5234778 ]\n",
      "episode 7, step 2, action: 0, observation: [ 0.00904129 -0.58539015 -0.01031328  0.80954003]\n",
      "episode 7, step 3, action: 0, observation: [-0.00266651 -0.7803693   0.00587752  1.0989611 ]\n",
      "episode 7, step 4, action: 0, observation: [-0.0182739  -0.97556806  0.02785674  1.3934823 ]\n",
      "episode 7, step 5, action: 0, observation: [-0.03778526 -1.1710255   0.05572639  1.6947434 ]\n",
      "episode 7, step 6, action: 0, observation: [-0.06120577 -1.3667445   0.08962125  2.0042412 ]\n",
      "episode 7, step 7, action: 0, observation: [-0.08854066 -1.5626793   0.12970608  2.3232772 ]\n",
      "episode 7, step 8, action: 0, observation: [-0.11979424 -1.7587194   0.17617163  2.6528943 ]\n",
      "episode 7, step 9, action: 0, observation: [-0.15496863 -1.9546722   0.22922951  2.9938009 ]\n",
      "Summary: total step: 10, total reward: 10.0\n",
      "episode 8, step 0, action: 0, observation: [-0.02890737 -0.17592676  0.0272445   0.32895282]\n",
      "episode 8, step 1, action: 0, observation: [-0.03242591 -0.37142575  0.03382355  0.6301014 ]\n",
      "episode 8, step 2, action: 0, observation: [-0.03985442 -0.56700295  0.04642558  0.9332416 ]\n",
      "episode 8, step 3, action: 0, observation: [-0.05119448 -0.76271945  0.06509041  1.2401443 ]\n",
      "episode 8, step 4, action: 0, observation: [-0.06644887 -0.95861405  0.0898933   1.552487  ]\n",
      "episode 8, step 5, action: 0, observation: [-0.08562115 -1.1546916   0.12094304  1.8718088 ]\n",
      "episode 8, step 6, action: 0, observation: [-0.10871498 -1.3509097   0.15837921  2.1994567 ]\n",
      "episode 8, step 7, action: 0, observation: [-0.13573317 -1.5471637   0.20236835  2.5365224 ]\n",
      "episode 8, step 8, action: 0, observation: [-0.16667645 -1.743268    0.2530988   2.8837671 ]\n",
      "Summary: total step: 9, total reward: 9.0\n",
      "episode 9, step 0, action: 0, observation: [ 0.02236747 -0.1718693   0.01803972  0.33533695]\n",
      "episode 9, step 1, action: 0, observation: [ 0.01893009 -0.36724326  0.02474646  0.63365364]\n",
      "episode 9, step 2, action: 0, observation: [ 0.01158522 -0.5627015   0.03741953  0.93402594]\n",
      "episode 9, step 3, action: 0, observation: [ 3.3119015e-04 -7.5830775e-01  5.6100048e-02  1.2382287e+00]\n",
      "episode 9, step 4, action: 0, observation: [-0.01483496 -0.95410365  0.08086462  1.5479453 ]\n",
      "episode 9, step 5, action: 0, observation: [-0.03391704 -1.1500978   0.11182353  1.8647242 ]\n",
      "episode 9, step 6, action: 0, observation: [-0.056919  -1.3462529  0.149118   2.1899266]\n",
      "episode 9, step 7, action: 0, observation: [-0.08384406 -1.5424699   0.19291654  2.5246642 ]\n",
      "episode 9, step 8, action: 0, observation: [-0.11469346 -1.7385708   0.24340983  2.8697252 ]\n",
      "Summary: total step: 9, total reward: 9.0\n"
     ]
    }
   ],
   "source": [
    "EPISODE_COUNT = 10\n",
    "STEP_COUNT = 500\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "for episode in range(EPISODE_COUNT):\n",
    "    observation, info = env.reset() # initial state\n",
    "    total_reward = []\n",
    "    total_step = 0\n",
    "    env.render()\n",
    "    for step in range(STEP_COUNT):\n",
    "        random_action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        total_step += 1\n",
    "        total_reward.append(reward)\n",
    "        print(f\"episode {episode}, step {step}, action: {action}, observation: {observation}\")\n",
    "        time.sleep(0.05)\n",
    "        if terminated or truncated:\n",
    "            print(f\"Summary: total step: {total_step}, total reward: {np.sum(total_reward)}\")\n",
    "            observation, info = env.reset()\n",
    "            time.sleep(1)\n",
    "            break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
